{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "384053b8",
   "metadata": {
    "title": "ruff: noqa: E402"
   },
   "outputs": [],
   "source": [
    "# ruff: noqa: E402\n",
    "import pandas as pd\n",
    "\n",
    "from jupyter_utils import JupyterUtils as JU\n",
    "\n",
    "ju = JU()\n",
    "DO_PROCESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db043d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(\"./data/raw/rotten_tomatoes_critic_reviews.csv\")\n",
    "df_movies = pd.read_csv(\"./data/raw/rotten_tomatoes_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28e1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove reviews with null scores or content\n",
    "df_reviews = df_reviews.dropna(subset=[\"review_score\", \"review_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c5e21b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(758709, 8)\n",
      "(758709, 9)\n"
     ]
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Normalize scores to 0-1\n",
    "GRADES = {\n",
    "    \"A+\": 12,\n",
    "    \"A\": 11,\n",
    "    \"A−\": 10,\n",
    "    \"B+\": 9,\n",
    "    \"B\": 8,\n",
    "    \"B−\": 7,\n",
    "    \"C+\": 6,\n",
    "    \"C\": 5,\n",
    "    \"C−\": 4,\n",
    "    \"D+\": 3,\n",
    "    \"D\": 2,\n",
    "    \"D−\": 1,\n",
    "    \"F\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_score(score):\n",
    "    \"\"\"docstring for convert_score\"\"\"\n",
    "    if \"/\" in score:\n",
    "        try:\n",
    "            num, den = score.split(\"/\")\n",
    "            num = float(Fraction(num))\n",
    "            den = float(Fraction(den))\n",
    "            if den > 0:\n",
    "                return num / den\n",
    "            else:\n",
    "                return np.nan\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # Remove white spaces\n",
    "    score = score.replace(\" \", \"\")\n",
    "\n",
    "    # Letter grade\n",
    "    if score in GRADES:\n",
    "        return GRADES[score] / 12\n",
    "\n",
    "    # Some values are numeric without \"/\", ignore them\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "df_reviews_ = df_reviews.copy()\n",
    "\n",
    "df_reviews_[\"score_norm\"] = df_reviews[\"review_score\"].apply(normalize_score)\n",
    "\n",
    "df_reviews_ = df_reviews_.dropna(subset=[\"score_norm\"])\n",
    "\n",
    "# Filter out erranous scores (e.g. 8/5)\n",
    "df_reviews_ = df_reviews_[df_reviews_[\"score_norm\"] <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b208519",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "      <th>cumulative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_binary</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483796</td>\n",
       "      <td>67.13</td>\n",
       "      <td>67.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236864</td>\n",
       "      <td>32.87</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count  percentage  cumulative\n",
       "score_binary                                \n",
       "1             483796       67.13       67.13\n",
       "0             236864       32.87      100.00"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ju.freq(df_reviews_, \"score_binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f88c4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to +ve -ve scores\n",
    "df_reviews_[\"score_binary\"] = df_reviews_[\"score_norm\"].apply(\n",
    "    lambda x: 1 if x > 0.5 else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0989a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50000  # number you want\n",
    "\n",
    "pos_samples = df_reviews_[df_reviews_[\"score_binary\"] == 1].sample(n, random_state=42)\n",
    "neg_samples = df_reviews_[df_reviews_[\"score_binary\"] == 0].sample(n, random_state=42)\n",
    "\n",
    "df_reviews__ = pd.concat([pos_samples, neg_samples], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc5a7068",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [16:10<00:00, 103.05it/s]\n"
     ]
    }
   ],
   "source": [
    "%%execute_if DO_PROCESS\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()  # enables df.progress_apply()\n",
    "\n",
    "# Download the English model\n",
    "# python -m space en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "# Remove stopwords and\n",
    "def preprocess_review(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [\n",
    "        token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "df_reviews__[\"preproced_review\"] = df_reviews__[\"review_content\"].progress_apply(\n",
    "    preprocess_review\n",
    ")\n",
    "\n",
    "df_reviews__.to_csv(\"./data/processed/rotten_tomatoes_critic_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ea8cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_reviews__ = pd.read_csv(\"./data/processed/rotten_tomatoes_critic_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00815e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /tmp/data/data.parquet\n"
     ]
    }
   ],
   "source": [
    "ju.vz(df_reviews__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89350572",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Accuracy per fold: [0.7532, 0.75885, 0.7522, 0.7526, 0.74965]\n",
      "Mean accuracy: 0.7533000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Remove reviews with null scores or content\n",
    "df_reviews__ = df_reviews__.dropna(subset=[\"preproced_review\"])\n",
    "X = df_reviews__[\"preproced_review\"]\n",
    "y = df_reviews__[\"score_binary\"]\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "tv = TfidfVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    X_train_bow = tv.fit_transform(X_train)\n",
    "    X_test_bow = tv.transform(X_test)\n",
    "\n",
    "    # clf = LogisticRegression(max_iter=200)\n",
    "    lr = LogisticRegression(penalty=\"l2\", max_iter=500, C=1, random_state=42)\n",
    "    lr.fit(X_train_bow, y_train)\n",
    "\n",
    "    preds = lr.predict(X_test_bow)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    fold_results.append(acc)\n",
    "\n",
    "print(\"Accuracy per fold:\", fold_results)\n",
    "print(\"Mean accuracy:\", sum(fold_results) / len(fold_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48db8a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    rotten_tomatoes_link  count\n",
      "13725  m/star_wars_the_rise_of_skywalker    672\n",
      "13447           m/solo_a_star_wars_story    634\n",
      "13724          m/star_wars_the_last_jedi    628\n",
      "13614         m/spider_man_far_from_home    624\n",
      "12243                 m/ready_player_one    606\n",
      "...                                  ...    ...\n",
      "3194                             m/basil      1\n",
      "3276                       m/beat_street      1\n",
      "9733       m/love_and_other_catastrophes      1\n",
      "3296               m/beautiful_something      1\n",
      "7327                           m/gumshoe      1\n",
      "\n",
      "[17618 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Visualization\n",
    "\n",
    "df_ = pd.merge(\n",
    "    df_reviews,\n",
    "    df_movies,\n",
    "    left_on=\"rotten_tomatoes_link\",\n",
    "    right_on=\"rotten_tomatoes_link\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "\n",
    "df__ = (\n",
    "    df_.groupby(\"rotten_tomatoes_link\")\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(\"count\", ascending=False)\n",
    ")\n",
    "print(df__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22715836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_reviews.copy()\n",
    "df = df_reviews[\n",
    "    (df_reviews[\"rotten_tomatoes_link\"] == \"m/star_wars_the_rise_of_skywalker\")\n",
    "    | (df_reviews[\"rotten_tomatoes_link\"] == \"m/solo_a_star_wars_story\")\n",
    "    | (df_reviews[\"rotten_tomatoes_link\"] == \"m/star_wars_the_last_jedi\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "reviews = [\n",
    "    \"This movie was fantastic and thrilling\",\n",
    "    \"I did not like the plot but loved the visuals\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_frequent_words(reviews, top_n=10):\n",
    "    words = []\n",
    "    for review in reviews:\n",
    "        doc = nlp(review)\n",
    "        # Keep only alphabetic words that are not stop words\n",
    "        words.extend(\n",
    "            [\n",
    "                token.text.lower()\n",
    "                for token in doc\n",
    "                if not token.is_stop and token.is_alpha\n",
    "            ]\n",
    "        )\n",
    "    freq = Counter(words)\n",
    "    return freq.most_common(top_n)\n",
    "\n",
    "\n",
    "# Group by movie and compute most frequent words\n",
    "result = (\n",
    "    df_[:10000]\n",
    "    .groupby(\"movie_title\")[\"review_content\"]\n",
    "    .apply(lambda x: get_frequent_words(x, top_n=5))\n",
    ")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
